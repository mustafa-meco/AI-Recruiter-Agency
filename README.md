# AI Recruiter Agency ğŸ¤–ğŸ’¼

An enterprise-grade AI-powered recruitment automation system featuring dual dashboards, intelligent agent orchestration, and persistent candidate management. Built with FastAPI, modern web technologies, and advanced LLM capabilities.

## ğŸŒŸ Key Features

### **Dual Dashboard Architecture**
- **ğŸ“ Candidate Portal** (`/`): Modern, glassmorphic UI for job seekers to analyze resumes and receive career guidance
- **ğŸ“Š Recruiter Dashboard** (`/recruiter`): Professional interface for bulk resume processing, screening, and hiring decisions
- **ğŸ”„ Unified Backend**: Single FastAPI application (`main.py`) serving both interfaces with shared agent infrastructure

### **Intelligent Agent System**
- **8 Specialized AI Agents**: Extractor, Enhancer, Analyzer, Matcher, Screener, Recommender, Advisor, Market Intelligence
- **Orchestrated Workflow**: Seamless data flow through extraction â†’ enhancement â†’ analysis â†’ matching â†’ screening â†’ recommendation
- **Dynamic Scoring**: Real-time evaluation with 0-100 scoring and confidence levels
- **Profile Enhancement**: AI-powered data standardization and enrichment

### **Advanced Matching & Intelligence**
- **Hybrid Job Matching**: Combines SQLite database jobs with live market trends (via DuckDuckGo search)
- **Market Intelligence**: Real-time job market analysis and trend detection
- **Multi-Source Results**: Database jobs + live market opportunities with source attribution

### **Enterprise Features**
- **Persistent Storage**: SQLite database for candidates and job listings
- **Duplicate Detection**: Intelligent file-based deduplication
- **Bulk Processing**: Sync entire resume folders with one click
- **Comprehensive Reports**: Full-stack analysis with screening scores, red flags, and recommendations

### **Flexible LLM Backend**
- **Multi-Provider Support**: Ollama (local) and Nebius AI (cloud)
- **Dynamic Switching**: Runtime provider selection
- **Configurable Models**: Easy model customization via `config.py`

## ğŸ—ï¸ System Architecture

### High-Level Overview

```mermaid
graph TB
    subgraph "Frontend Layer"
        CP[Candidate Portal<br/>Modern UI]
        RD[Recruiter Dashboard<br/>Professional UI]
    end
    
    subgraph "FastAPI Backend - main.py"
        API[API Routes]
        ORCH[Orchestrator Agent]
    end
    
    subgraph "AI Agent Brain"
        EXT[Extractor<br/>PDF â†’ JSON]
        ENH[Profile Enhancer<br/>Data Standardization]
        ANA[Analyzer<br/>Skills & Experience]
        MAT[Matcher<br/>Job Matching]
        SCR[Screener<br/>Qualification Check]
        REC[Recommender<br/>Hiring Decision]
        ADV[Advisor<br/>Career Guidance]
        MI[Market Intelligence<br/>Live Trends]
    end
    
    subgraph "Data Layer"
        DB[(SQLite Database<br/>Jobs + Candidates)]
        WEB[Live Market Data<br/>DuckDuckGo]
    end
    
    subgraph "LLM Providers"
        OLLAMA[Ollama<br/>Local]
        NEBIUS[Nebius AI<br/>Cloud]
    end
    
    CP --> API
    RD --> API
    API --> ORCH
    
    ORCH --> EXT --> ENH --> ANA --> MAT
    MAT --> SCR --> REC
    MAT --> ADV
    MAT <--> MI
    
    MAT <--> DB
    MI <--> WEB
    
    EXT & ANA & MAT & SCR & REC & ADV & MI -.-> OLLAMA
    EXT & ANA & MAT & SCR & REC & ADV & MI -.-> NEBIUS
    
    style CP fill:#9f9,stroke:#333,stroke-width:2px
    style RD fill:#ff9,stroke:#333,stroke-width:2px
    style ORCH fill:#f99,stroke:#333,stroke-width:2px
    style DB fill:#99f,stroke:#333,stroke-width:2px
```

### Data Flow Architecture

```mermaid
graph LR
    subgraph "Input"
        PDF[Resume PDF]
    end
    
    subgraph "Processing Stages"
        S1[1. Extraction<br/>Text + Structure]
        S2[2. Enhancement<br/>Standardization]
        S3[3. Analysis<br/>Skills + Experience]
        S4[4. Matching<br/>Jobs + Market]
        S5[5. Screening<br/>Score + Flags]
        S6[6. Recommendation<br/>Hiring Decision]
    end
    
    subgraph "Output"
        REPORT[Full Report JSON]
        UI[Dashboard Display]
        STORAGE[(Database Storage)]
    end
    
    PDF --> S1 --> S2 --> S3 --> S4 --> S5 --> S6
    S6 --> REPORT
    REPORT --> UI
    REPORT --> STORAGE
    
    style PDF fill:#e1f5ff
    style REPORT fill:#ffe1e1
    style STORAGE fill:#e1ffe1
```

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+**
- **Ollama** installed and running ([Download](https://ollama.com/))
- **Model**: `gemma-2-2b-it` (or configure your preferred model)
  ```bash
  ollama pull google/gemma-2-2b-it
  ```
- **(Optional)** Nebius AI API Key for cloud-based processing

### Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd AI-Recruiter-Agency
   ```

2. **Set up virtual environment**:
   ```bash
   python -m venv venv
   
   # Windows
   .\venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure LLM Provider** (Optional):
   - Edit `config.py` to set your preferred provider and model
   - For Nebius AI, set your API key in `config.py`

### Running the Application

**Unified FastAPI Server** (Serves both dashboards):
```bash
uvicorn main:app --reload
```

**Access Points**:
- ğŸ“ **Candidate Portal**: http://localhost:8000/
- ğŸ“Š **Recruiter Dashboard**: http://localhost:8000/recruiter

**Legacy Streamlit Dashboard** (Optional):
```bash
streamlit run app.py
```
*Access at: http://localhost:8501*

## ğŸ“– Usage Guide

### For Recruiters

1. **Navigate to Recruiter Dashboard**: http://localhost:8000/recruiter
2. **Sync Resumes Folder**: Click "Sync Resumes Folder" to process all PDFs in `resumes/` directory
3. **Or Upload Manually**: Drag and drop resume files
4. **View Candidates**: Browse the candidate table with scores and recommendations
5. **Deep Dive**: Click "View Report" to see:
   - **Analysis Tab**: Profile, skills, education, achievements
   - **Job Matches Tab**: Top job fits with match scores (Database + Live Market)
   - **Screening Tab**: Screening score, report, and red flags
   - **Recommendation Tab**: Hiring status and final verdict

### For Candidates

1. **Navigate to Candidate Portal**: http://localhost:8000/
2. **Upload Resume**: Drag and drop your PDF resume
3. **Receive Instant Analysis**:
   - Professional profile summary
   - Skills assessment
   - Job matches with compatibility scores
   - Personalized career advice and improvement tips

## ğŸ“ Project Structure

```
AI-Recruiter-Agency/
â”œâ”€â”€ agents/                      # AI Agent Brain
â”‚   â”œâ”€â”€ base_agent.py           # Base class with LLM integration
â”‚   â”œâ”€â”€ orchestrator.py         # Workflow coordinator
â”‚   â”œâ”€â”€ extractor_agent.py      # PDF â†’ JSON extraction
â”‚   â”œâ”€â”€ profile_enhancer_agent.py # Data standardization
â”‚   â”œâ”€â”€ analyzer_agent.py       # Skills & experience analysis
â”‚   â”œâ”€â”€ matcher_agent.py        # Job matching logic
â”‚   â”œâ”€â”€ screener_agent.py       # Qualification screening
â”‚   â”œâ”€â”€ recommender_agent.py    # Hiring recommendations
â”‚   â”œâ”€â”€ candidate_advisor_agent.py # Career guidance
â”‚   â””â”€â”€ market_intelligence_agent.py # Live market trends
â”‚
â”œâ”€â”€ db/                          # Database Layer
â”‚   â”œâ”€â”€ database.py             # SQLite operations
â”‚   â”œâ”€â”€ schema.sql              # Database schema
â”‚   â””â”€â”€ jobs.sqlite             # Job listings + candidates
â”‚
â”œâ”€â”€ templates/                   # Frontend Templates
â”‚   â”œâ”€â”€ index.html              # Candidate Portal UI
â”‚   â””â”€â”€ recruiter_dashboard.html # Recruiter Dashboard UI
â”‚
â”œâ”€â”€ static/                      # Frontend Assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css           # Candidate Portal styles
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ app.js              # Candidate Portal logic
â”‚
â”œâ”€â”€ resumes/                     # Resume storage folder
â”œâ”€â”€ uploads/                     # Temporary upload directory
â”‚
â”œâ”€â”€ main.py                      # Unified FastAPI application
â”œâ”€â”€ app.py                       # Legacy Streamlit dashboard
â”œâ”€â”€ config.py                    # Configuration & LLM settings
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

## ğŸ¯ Core Agents Explained

| Agent | Purpose | Key Features |
|-------|---------|--------------|
| **Extractor** | PDF parsing | Converts resumes to structured JSON with personal info, experience, education, skills |
| **Profile Enhancer** | Data quality | Standardizes and enriches extracted data for better downstream accuracy |
| **Analyzer** | Deep analysis | Evaluates technical skills, experience level, achievements, and education |
| **Market Intelligence** | Live trends | Searches DuckDuckGo for current job market data and trending roles |
| **Matcher** | Job matching | Combines database jobs + live market data, calculates compatibility scores (0-100) |
| **Screener** | Qualification check | Generates screening score (0-100), identifies red flags, provides detailed report |
| **Advisor** | Career guidance | Offers personalized tips for resume improvement and career development |
| **Recommender** | Hiring decision | Provides final verdict (Recommended/Not Recommended/Pending) with justification |

## ğŸ”§ Configuration

### LLM Provider Setup

Edit `config.py`:

```python
# Default provider: "ollama" or "nebius"
DEFAULT_PROVIDER = "nebius"

# Ollama settings
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_MODEL = "llama3.2"

# Nebius settings
NEBIUS_API_KEY = "your-api-key-here"
NEBIUS_MODEL = "google/gemma-2-2b-it"
```

### Database Configuration

The system automatically initializes the SQLite database with:
- **Jobs table**: Pre-seeded with sample job listings
- **Candidates table**: Stores processed candidate data with full reports

## ğŸ› Troubleshooting

### Common Issues

**Issue**: "Ollama connection refused"
- **Solution**: Ensure Ollama is running (`ollama serve`)

**Issue**: "Model not found"
- **Solution**: Pull the required model (`ollama pull google/gemma-2-2b-it`)

**Issue**: "Duplicate candidates appearing"
- **Solution**: Clear database and re-sync (`rm db/jobs.sqlite` then restart)

**Issue**: "Screening/Recommendation tabs empty"
- **Solution**: Refresh browser to load latest frontend updates

## ğŸš§ Recent Updates

- âœ… Unified FastAPI backend serving both dashboards
- âœ… Persistent candidate storage with SQLite
- âœ… Duplicate detection and prevention
- âœ… Screening and Recommendation tab population in modal
- âœ… Text wrapping for recommendation column
- âœ… Focused context for improved LLM accuracy
- âœ… Dynamic scoring system (0-100 scale)
- âœ… Live market intelligence integration
- âœ… Enhanced error handling and logging

## ğŸ“Š Performance Notes

- **Processing Time**: ~30-60 seconds per resume (depends on LLM provider)
- **Bulk Processing**: Processes resumes sequentially with duplicate skipping
- **Database**: Lightweight SQLite, suitable for 1000+ candidates
- **Scalability**: For production use, consider PostgreSQL and async processing

## ğŸ“š Dataset Acknowledgment

This project uses sample CV data from the [Sample CVs Dataset for Analysis](https://www.kaggle.com/datasets/hussnainmushtaq/sample-cvs-dataset-for-analysis) available on Kaggle. The dataset provides realistic resume examples for testing and demonstrating the AI recruitment system's capabilities.

**Dataset Source**: Hussnain Mushtaq - Kaggle
**License**: Check dataset page for specific licensing terms
**Usage**: Testing, development, and demonstration purposes

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit pull requests or open issues for bugs and feature requests.

## ğŸ“„ License

MIT License - see LICENSE file for details

---

**Built with â¤ï¸ using FastAPI, LLMs, and Modern Web Technologies**
